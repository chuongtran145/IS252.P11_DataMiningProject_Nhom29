import streamlit as st
import pandas as pd

# CSS b·∫£ng D·ªØ li·ªáu ƒë√£ t·∫£i l√™n
custom_data_table_css = """
    <style>
        .data-table-container {
            display: flex;
            justify-content: center; /* CƒÉn gi·ªØa b·∫£ng */
            align-items: center;
            margin: 20px auto; /* CƒÉn gi·ªØa b·∫£ng */
            max-width: 100%; /* Gi·ªõi h·∫°n chi·ªÅu r·ªông */
            overflow-x: auto; /* Th√™m cu·ªôn ngang n·∫øu b·∫£ng qu√° r·ªông */
        }
        .data-table {
            border-collapse: collapse;
            font-size: 16px; /* K√≠ch th∆∞·ªõc ch·ªØ */
            font-family: Arial, sans-serif;
            width: 100%; /* Chi·∫øm to√†n b·ªô chi·ªÅu r·ªông khung */
            text-align: center;
            border: 1px solid #ddd; /* Vi·ªÅn b·∫£ng */
            color: #023047;
        }

        .data-table th {
            background-color: #27b8b5; /* M√†u n·ªÅn ti√™u ƒë·ªÅ */
            color: #FFFFFF; /* M√†u ch·ªØ ti√™u ƒë·ªÅ */
            padding: 10px;
            text-align: center;
        }

        .data-table td {
            padding: 8px 10px;
            text-align: center;
        }

        .data-table tr:nth-child(even) {
            background-color: #e1fcfc; /* M√†u n·ªÅn d√≤ng ch·∫µn */
        }

        .data-table tr:nth-child(odd) {
            background-color: #ffffff; /* M√†u n·ªÅn d√≤ng l·∫ª */
        }

        .data-table tr:hover {
            background-color: #8ECAE6; /* M√†u n·ªÅn khi hover */
            color: #000000; /* M√†u ch·ªØ khi hover */
        }
    </style>
"""

def draw_table(df):
    data_html = df.to_html(
        index=False,
        classes='data-table',  # Th√™m class ƒë·ªÉ √°p d·ª•ng CSS
        border=0
    )
    # Hi·ªÉn th·ªã CSS v√† b·∫£ng HTML
    st.markdown(custom_data_table_css, unsafe_allow_html=True)
    st.markdown(
        f'<div class="data-table-container">{data_html}</div>', unsafe_allow_html=True) 

def app():
    st.subheader("1Ô∏è‚É£ Ch·ªçn t·ªáp tin:")
    uploaded_file = st.file_uploader("T·∫£i l√™n file CSV", type=["csv"])

    if uploaded_file is not None:
        # ƒê·ªçc d·ªØ li·ªáu t·ª´ file Excel
        try:
            df = pd.read_csv(uploaded_file)

            # Hi·ªÉn th·ªã b·∫£ng d·ªØ li·ªáu tr√™n giao di·ªán
            st.info("D·ªØ li·ªáu ƒë√£ t·∫£i l√™n:")
            # Chuy·ªÉn DataFrame th√†nh HTML v·ªõi class ƒë·ªÉ hi·ªÉn th·ªã b·∫£ng
            draw_table(df)
        except Exception as e:
            st.error(f"L·ªói khi ƒë·ªçc file: {e}")

        # Mapping d·ªØ li·ªáu ƒë·ªãnh t√≠nh sang s·ªë
        mapping = {
            "Troi": {"Trong": 0, "May": 1 },
            "Gio": {"Bac": 0, "Nam": 1},
            "Apsuat": {"Cao": 1, "TB": 2, "Thap": 3},
            "Ketqua": {"Kmua": 0, "Mua": 1}
        }
        reverse_mapping = {col: {v: k for k, v in mapping.items()}
                           for col, mapping in mapping.items()}

        for col, col_mapping in mapping.items():
            if col in df.columns:
                df[col] = df[col].map(col_mapping)

        # L·∫•y danh s√°ch c√°c c·ªôt thu·ªôc t√≠nh
        columns = df.columns.tolist()
        decision_column = columns[-1]  # C·ªôt thu·ªôc t√≠nh quy·∫øt ƒë·ªãnh (cu·ªëi c√πng)
        attributes = columns[1:-1]  # C√°c thu·ªôc t√≠nh (tr·ª´ c·ªôt quy·∫øt ƒë·ªãnh)
        st.subheader("2Ô∏è‚É£ Ch·ªçn c√°ch t√≠nh mu·ªën th·ª±c hi·ªán:")
        with st.container(border=1):
            # Ch·ªçn c√°ch t√≠nh mu·ªën th·ª±c hi·ªán
            selected_method = st.selectbox(
                "Ch·ªçn c√°ch t√≠nh mu·ªën th·ª±c hi·ªán:",
                ["T√≠nh x·∫•p x·ªâ", "Kh·∫£o s√°t s·ª± ph·ª• thu·ªôc", "T√≠nh c√°c r√∫t g·ªçn"]
            )
            # Giao di·ªán theo t·ª´ng ph∆∞∆°ng ph√°p
            if selected_method == "T√≠nh x·∫•p x·ªâ":
                # Ch·ªçn t·∫≠p thu·ªôc t√≠nh
                st.markdown(
                    '<label for="tap-thuoc-tinh">Ch·ªçn t·∫≠p thu·ªôc t√≠nh:</label>', unsafe_allow_html=True)
                selected_attributes = st.multiselect(
                    "Ch·ªçn t·∫≠p thu·ªôc t√≠nh:", attributes)

                # T·∫°o t·ª´ ƒëi·ªÉn √°nh x·∫° ng∆∞·ª£c t·ª´ s·ªë sang ch·ªØ (reverse mapping)
                reverse_mapping_decision = {v: k for k,
                v in mapping[decision_column].items()}

                # L·∫•y danh s√°ch c√°c gi√° tr·ªã thu·ªôc t√≠nh quy·∫øt ƒë·ªãnh d∆∞·ªõi d·∫°ng ch·ªØ
                unique_decision_values = [reverse_mapping_decision[val]
                                          for val in df[decision_column].dropna().unique()]

                # Hi·ªÉn th·ªã dropdown v·ªõi gi√° tr·ªã ch·ªØ
                decision_value_label = st.selectbox(
                    "Ch·ªçn gi√° tr·ªã c·ªßa thu·ªôc t√≠nh quy·∫øt ƒë·ªãnh:",
                    unique_decision_values
                )

                # Chuy·ªÉn gi√° tr·ªã ƒë∆∞·ª£c ch·ªçn t·ª´ ch·ªØ v·ªÅ s·ªë ƒë·ªÉ t√≠nh to√°n
                decision_value = {v: k for k, v in reverse_mapping_decision.items()}[
                    decision_value_label]

            elif selected_method == "Kh·∫£o s√°t s·ª± ph·ª• thu·ªôc":
                # Ch·ªçn t·∫≠p thu·ªôc t√≠nh
                st.markdown(
                    '<label for="tap-thuoc-tinh">Ch·ªçn t·∫≠p thu·ªôc t√≠nh:</label>', unsafe_allow_html=True)
                selected_attributes = st.multiselect(
                    "Ch·ªçn t·∫≠p thu·ªôc t√≠nh", attributes)

        # N√∫t t√≠nh to√°n
        if st.button("Th·ª±c hi·ªán"):
            if selected_method == "T√≠nh x·∫•p x·ªâ":
                if not selected_attributes:
                    st.write("Vui l√≤ng ch·ªçn t·∫≠p thu·ªôc t√≠nh.")
                else:
                    # H√†m t√≠nh x·∫•p x·ªâ d∆∞·ªõi
                    def calculate_lower_approximation(dataframe, attrs, decision_val):
                        lower_indices = [
                            idx + 1 for idx, row in dataframe.iterrows()
                            if (dataframe[(dataframe[attrs] == tuple(row[attrs])).all(axis=1)][decision_column] == decision_val).all()
                        ]
                        return len(lower_indices), lower_indices

                    # H√†m t√≠nh x·∫•p x·ªâ tr√™n
                    def calculate_upper_approximation(dataframe, attrs, decision_val):
                        upper_indices = [
                            idx + 1 for idx, row in dataframe.iterrows()
                            if decision_val in dataframe[(dataframe[attrs] == tuple(row[attrs])).all(axis=1)][decision_column].values
                        ]
                        return len(upper_indices), upper_indices

                    # Th·ª±c hi·ªán t√≠nh to√°n x·∫•p x·ªâ
                    lower_count, lower_set = calculate_lower_approximation(df, selected_attributes, decision_value)
                    upper_count, upper_set = calculate_upper_approximation(df, selected_attributes, decision_value)

                    # Hi·ªÉn th·ªã k·∫øt qu·∫£
                    with st.container(border=1):
                        st.markdown("üîé **:blue[K·∫øt qu·∫£:]**")
                        st.info(f"**X·∫•p x·ªâ d∆∞·ªõi:** {lower_count}  -  **t·∫≠p gi√° tr·ªã:** {set(lower_set)}")
                        st.info(f"**X·∫•p x·ªâ tr√™n:** {upper_count}  -  **t·∫≠p gi√° tr·ªã:** {set(upper_set)}")

            elif selected_method == "Kh·∫£o s√°t s·ª± ph·ª• thu·ªôc":
                if not selected_attributes:
                    st.write("Vui l√≤ng ch·ªçn t·∫≠p thu·ªôc t√≠nh.")
                else:
                    decision_column = columns[-1]
                    df = df.dropna(subset=selected_attributes + [decision_column])

                    # H√†m t√≠nh x·∫•p x·ªâ d∆∞·ªõi
                    def lower_approximation_count(dataframe, attrs, decision_col):
                        return sum(
                            (dataframe[(dataframe[attrs] == tuple(row[attrs])).all(axis=1)][decision_col] == row[decision_col]).all()
                            for _, row in dataframe.iterrows()
                        )

                    # H√†m t√≠nh x·∫•p x·ªâ tr√™n
                    def upper_approximation_count(dataframe, attrs, decision_col):
                        return sum(
                            len(dataframe[(dataframe[attrs] == tuple(row[attrs])).all(axis=1)][decision_col])
                            for _, row in dataframe.iterrows()
                        )

                    # T√≠nh to√°n v√† hi·ªÉn th·ªã k·∫øt qu·∫£
                    lower_count = lower_approximation_count(df, selected_attributes, decision_column)
                    upper_count = upper_approximation_count(df, selected_attributes, decision_column)

                    dependency_ratio = lower_count / len(df) if len(df) > 0 else 0
                    st.write(f"H·ªá s·ªë ph·ª• thu·ªôc (k): {dependency_ratio:.2f}")

                    accuracy = lower_count / upper_count if upper_count > 0 else 0
                    st.write(f"ƒê·ªô ch√≠nh x√°c: {accuracy:.2f}")

            elif selected_method == "T√≠nh c√°c r√∫t g·ªçn":
                decision_column = df.columns[-1]
                attributes = df.columns[1:-1]

                # H√†m t√¨m r√∫t g·ªçn
                def find_minimal_reducts(dataframe, decision_col, attrs):
                    from itertools import combinations

                    all_reducts = [
                        set(subset) for r in range(1, len(attrs) + 1)
                        for subset in combinations(attrs, r)
                        if dataframe.groupby(list(subset))[decision_col].nunique().eq(1).all()
                    ]

                    return [
                        reduct for reduct in all_reducts
                        if not any(reduct > other for other in all_reducts if reduct != other)
                    ]

                # H√†m sinh lu·∫≠t ph√¢n l·ªõp
                def generate_classification_rules_with_reverse_mapping(df, reduct, decision_column, reverse_mapping):
                        rules = []
                        # L·ªçc d·ªØ li·ªáu theo t·∫≠p r√∫t g·ªçn
                        for _, subset in df.groupby(list(reduct)):
                            # T√¨m gi√° tr·ªã duy nh·∫•t c·ªßa c·ªôt quy·∫øt ƒë·ªãnh
                            decision_values = subset[decision_column].unique()
                            if len(decision_values) == 1:  # ƒê·∫£m b·∫£o ch·ªâ c√≥ 1 gi√° tr·ªã duy nh·∫•t
                                decision_value = decision_values[0]
                                # Chuy·ªÉn gi√° tr·ªã s·ªë sang ch·ªØ d·ª±a tr√™n reverse_mapping
                                decision_label = reverse_mapping[decision_column].get(
                                    decision_value, decision_value)

                                # T·∫°o ƒëi·ªÅu ki·ªán v·ªõi d·ªØ li·ªáu ƒë√£ chuy·ªÉn v·ªÅ d·∫°ng ch·ªØ
                                conditions = " v√† ".join(
                                    [
                                        f"{col} = '{reverse_mapping[col].get(subset[col].iloc[0], subset[col].iloc[0])}'"
                                        for col in reduct
                                    ]
                                )
                                rules.append(f"N·∫øu {conditions} th√¨ {decision_column} = '{decision_label}'")
                        return rules

                # T√¨m c√°c t·∫≠p r√∫t g·ªçn
                reducts = find_minimal_reducts(df, decision_column, attributes)

                # Hi·ªÉn th·ªã k·∫øt qu·∫£
                st.write("K·∫øt qu·∫£:")
                if reducts:
                    st.write("C√°c r√∫t g·ªçn t√¨m ƒë∆∞·ª£c:")
                    for reduct in reducts:
                        st.write(", ".join(reduct))

                    # Ch·ªçn t·∫≠p r√∫t g·ªçn ƒë·∫ßu ti√™n ƒë·ªÉ t·∫°o lu·∫≠t ph√¢n l·ªõp
                    reduct = list(reducts[0])  # L·∫•y r√∫t g·ªçn ƒë·∫ßu ti√™n
                    classification_rules = generate_classification_rules_with_reverse_mapping(
                        df, reduct, decision_column, reverse_mapping
                    )

                    # Hi·ªÉn th·ªã 3 lu·∫≠t ph√¢n l·ªõp ƒë·∫ßu ti√™n
                    st.write("ƒê·ªÅ xu·∫•t c√°c lu·∫≠t ph√¢n l·ªõp ch√≠nh x√°c 100%:")
                    for rule in classification_rules[:3]:
                        st.write(rule)
                else:
                    st.write("Kh√¥ng t√¨m th·∫•y r√∫t g·ªçn.")
    else:
        st.warning("Vui l√≤ng t·∫£i t·ªáp d·ªØ li·ªáu ƒë·ªÉ ti·∫øp t·ª•c")
